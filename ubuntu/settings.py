"""
Django settings for ubuntu project.

Generated by 'django-admin startproject' using Django 5.2.1.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/5.2/ref/settings/
"""

import os
import dj_database_url
from pathlib import Path
from datetime import timedelta
from urllib.parse import urlparse

from config import DjangoConfig, CeleryConfig

# Validar configuración cargada desde DjangoConfig
DjangoConfig.validate()
# Validar configuración de Celery (no es estricto, solo advertencias)
CeleryConfig.validate()


# ============================================================================
# PATHS Y CONFIGURACIÓN BASE
# ============================================================================

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent

#* SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = DjangoConfig.SECRET_KEY 

#* SECURITY WARNING: don't run with debug turned on in production!
DEBUG = DjangoConfig.DEBUG

#* Configuración de ALLOWED_HOSTS
ALLOWED_HOSTS = DjangoConfig.ALLOWED_HOSTS

#* Configuración de WS_ALLOWED_ORIGINS
WS_ALLOWED_ORIGINS = DjangoConfig.WS_ALLOWED_ORIGINS

#* Configuración de WS_ALLOWED_ORIGIN_REGEXES
WS_ALLOWED_ORIGIN_REGEXES = DjangoConfig.WS_ALLOWED_ORIGIN_REGEXES

# ============================================================================
# APLICACIONES INSTALADAS
# ============================================================================

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'corsheaders',
    'rest_framework',
    'django_filters',
    'channels',  # Soporte WebSockets
    'udid.apps.UdidConfig',  # Usar AppConfig para inicialización de PanAccess
]

# ============================================================================
# CONFIGURACIÓN DE CHANNELS
# ============================================================================
# ASGI_APPLICATION: Ruta al módulo ASGI que maneja las conexiones WebSocket y HTTP asíncronas
# Channels usa ASGI (Asynchronous Server Gateway Interface) en lugar de WSGI para soportar WebSockets
ASGI_APPLICATION = 'ubuntu.asgi.application'

# REDIS_URL: URL de conexión a Redis (usado como backend para Channel Layers y cache)
# Por defecto, usar localhost:6379 si no está configurado (desarrollo local)
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

# REDIS_SENTINEL: Configuración de Redis Sentinel para alta disponibilidad y failover automático
# Formato: "host1:puerto1,host2:puerto2,host3:puerto3" (múltiples instancias Sentinel)
# Si está configurado, se usa Sentinel en lugar de conexión directa a Redis
# None = no usar Sentinel (conexión directa)
REDIS_SENTINEL = os.getenv("REDIS_SENTINEL", None)

# REDIS_SENTINEL_MASTER: Nombre del master de Redis que Sentinel debe monitorear
# Este es el nombre del servicio master configurado en la configuración de Sentinel
REDIS_SENTINEL_MASTER = os.getenv("REDIS_SENTINEL_MASTER", "mymaster")

# Parsear REDIS_SENTINEL: Convierte el string de configuración en lista de tuplas (host, puerto)
# Ejemplo: "192.168.1.1:26379,192.168.1.2:26379" -> [("192.168.1.1", 26379), ("192.168.1.2", 26379)]
if REDIS_SENTINEL:
    REDIS_SENTINEL = [
        (h, int(p)) for h, p in (hp.split(":") for hp in REDIS_SENTINEL.split(","))
    ]
else:
    REDIS_SENTINEL = None

# REDIS_SOCKET_CONNECT_TIMEOUT: Tiempo máximo (segundos) para establecer conexión con Redis
# Si Redis no responde en este tiempo, se considera fallo de conexión
REDIS_SOCKET_CONNECT_TIMEOUT = int(os.getenv("REDIS_SOCKET_CONNECT_TIMEOUT", "5"))

# REDIS_SOCKET_TIMEOUT: Tiempo máximo (segundos) para esperar respuesta de Redis en operaciones
# Si Redis no responde en este tiempo, se considera timeout de operación
REDIS_SOCKET_TIMEOUT = int(os.getenv("REDIS_SOCKET_TIMEOUT", "5"))

# REDIS_RETRY_ON_TIMEOUT: Si es True, reintenta automáticamente operaciones que fallan por timeout
# Útil para manejar picos de carga temporal donde Redis puede tardar más en responder
REDIS_RETRY_ON_TIMEOUT = os.getenv("REDIS_RETRY_ON_TIMEOUT", "True").lower() == "true"

# REDIS_MAX_CONNECTIONS: Número máximo de conexiones simultáneas al pool de conexiones de Redis
# Configuración estándar: 100 (50 para rate limiting + 50 para WebSockets)
# Configuración optimizada para 32GB RAM / 32 cores / 3000 requests: 300
# Configuración optimizada para 64GB RAM / 32 cores / 5000-7000 requests: 400
# Configuración optimizada para 124GB RAM / 64 cores / 10000-15000 requests: 600
# Más conexiones = mejor rendimiento bajo carga, pero más recursos del servidor Redis
REDIS_MAX_CONNECTIONS = int(os.getenv("REDIS_MAX_CONNECTIONS", "100"))


# ============================================================================
# CHANNEL LAYERS (comunicación WS y backend asíncrono)
# ============================================================================

# REDIS_CHANNEL_LAYER_URL: URL específica de Redis para Channel Layers (WebSockets y mensajería asíncrona)
# Permite separar el Redis de WebSockets del Redis de cache/rate limiting si es necesario
# Si no está configurado, se usa REDIS_URL por defecto
REDIS_CHANNEL_LAYER_URL = os.getenv("REDIS_CHANNEL_LAYER_URL", REDIS_URL)

# REDIS_RATE_LIMIT_URL: URL específica de Redis para rate limiting (control de frecuencia de peticiones)
# Permite usar un Redis separado para rate limiting si necesitas escalar independientemente
# Default: mismo que REDIS_URL (comparte Redis con Channel Layers)
REDIS_RATE_LIMIT_URL = os.getenv("REDIS_RATE_LIMIT_URL", REDIS_URL)

# host_cfg: Diccionario de configuración para la conexión a Redis en Channel Layers
# Contiene la dirección y opcionalmente configuración SSL si se usa rediss:// (Redis con TLS)
host_cfg = {"address": REDIS_CHANNEL_LAYER_URL}

# Detectar si se usa Redis con TLS (rediss://) y habilitar SSL automáticamente
# channels-redis detecta el esquema "rediss" y configura SSL automáticamente
if urlparse(REDIS_CHANNEL_LAYER_URL).scheme == "rediss":
    # Si usas TLS, channels-redis lo maneja automáticamente
    host_cfg["ssl"] = True

# Manejo de Sentinel o conexión directa
# Si REDIS_SENTINEL está configurado, se usa configuración de alta disponibilidad
if REDIS_SENTINEL:
    # Configuración con Redis Sentinel: soporte real para alta disponibilidad y failover automático
    # Sentinel monitorea múltiples instancias de Redis y cambia automáticamente si el master falla
    CHANNEL_LAYERS = {
        "default": {
            # BACKEND: Backend de Channels que usa Redis como almacenamiento de mensajes
            # channels_redis es el backend oficial que permite comunicación entre procesos/servidores
            "BACKEND": "channels_redis.core.RedisChannelLayer",
            "CONFIG": {
                # hosts: Lista de configuraciones de hosts de Redis
                # Con Sentinel, se especifican los sentinels y el nombre del master
                "hosts": [{
                    # sentinels: Lista de tuplas (host, puerto) de las instancias Sentinel
                    # Sentinel se encarga de encontrar el master actual automáticamente
                    "sentinels": REDIS_SENTINEL,
                    # master_name: Nombre del servicio master que Sentinel debe monitorear
                    # Debe coincidir con el nombre configurado en la configuración de Sentinel
                    "master_name": REDIS_SENTINEL_MASTER,
                    # db: Número de base de datos de Redis a usar (0-15, por defecto 0)
                    "db": 0,
                }],
                # capacity: Número máximo de mensajes que se pueden almacenar en un canal antes de bloquear
                # Si un canal alcanza este límite, los nuevos mensajes esperan hasta que haya espacio
                # Configuración estándar: 2000 mensajes (default: 100)
                # Configuración optimizada para 32GB RAM / 32 cores / 3000 requests: 5000 mensajes
                # Configuración optimizada para 64GB RAM / 32 cores / 5000-7000 requests: 10000 mensajes
                # Configuración optimizada para 124GB RAM / 64 cores / 10000-15000 requests: 20000 mensajes
                "capacity": int(os.getenv("CHANNEL_LAYERS_CAPACITY", "2000")),
                # expiry: Tiempo de expiración de mensajes en segundos
                # Los mensajes no leídos se eliminan automáticamente después de este tiempo
                # Previene acumulación infinita de mensajes en canales abandonados
                "expiry": int(os.getenv("CHANNEL_LAYERS_EXPIRY", "10")),
                # group_expiry: Tiempo en segundos antes de que un grupo de WebSocket expire
                # Los grupos permiten enviar mensajes a múltiples consumidores WebSocket simultáneamente
                # 900 segundos = 15 minutos de persistencia del grupo
                # Configuración optimizada para alta carga: aumentar a 1800 (30 minutos)
                "group_expiry": int(os.getenv("CHANNEL_LAYERS_GROUP_EXPIRY", "900")),
            },
        }
    }
else:
    # Configuración normal de Redis directo: conexión simple sin alta disponibilidad
    # Usado en desarrollo o cuando no necesitas failover automático
    CHANNEL_LAYERS = {
        "default": {
            # BACKEND: Backend de Channels que usa Redis como almacenamiento de mensajes
            "BACKEND": "channels_redis.core.RedisChannelLayer",
            "CONFIG": {
                # hosts: Lista de configuraciones de hosts de Redis
                # Con conexión directa, se especifica la URL completa del servidor Redis
                "hosts": [host_cfg],
                # capacity: Número máximo de mensajes por canal antes de bloquear (2000 mensajes)
                # Configuración optimizada para 32GB RAM / 32 cores / 3000 requests: 5000 mensajes
                # Configuración optimizada para 64GB RAM / 32 cores / 5000-7000 requests: 10000 mensajes
                # Configuración optimizada para 124GB RAM / 64 cores / 10000-15000 requests: 20000 mensajes
                "capacity": int(os.getenv("CHANNEL_LAYERS_CAPACITY", "2000")),
                # expiry: Tiempo de expiración de mensajes no leídos (10 segundos)
                "expiry": int(os.getenv("CHANNEL_LAYERS_EXPIRY", "10")),
                # group_expiry: Tiempo de persistencia de grupos WebSocket (900 segundos = 15 minutos)
                # Configuración optimizada para alta carga: aumentar a 1800 (30 minutos)
                "group_expiry": int(os.getenv("CHANNEL_LAYERS_GROUP_EXPIRY", "900")),
            },
        }
    }


# ============================================================================
# PARÁMETROS DE UDID / CARGA / CONCURRENCIA
# ============================================================================

# Tiempo máximo de espera del WS antes de responder "timeout" (segundos)
UDID_WAIT_TIMEOUT_AUTOMATIC = int(os.getenv("UDID_WAIT_TIMEOUT_AUTOMATIC", "180"))  # Validación automática: 90s
UDID_WAIT_TIMEOUT_MANUAL = int(os.getenv("UDID_WAIT_TIMEOUT_MANUAL", "180"))  # Validación manual: 180s

# Compatibilidad hacia atrás
UDID_WAIT_TIMEOUT = int(os.getenv("UDID_WAIT_TIMEOUT", str(UDID_WAIT_TIMEOUT_AUTOMATIC)))
# Si querés habilitar un polling de respaldo (además del evento push)
UDID_ENABLE_POLLING = os.getenv("UDID_ENABLE_POLLING", "0") == "1"
UDID_POLL_INTERVAL = int(os.getenv("UDID_POLL_INTERVAL", "2"))

# Configuración para pruebas de carga (aumentar límites temporalmente)
UDID_EXPIRATION_MINUTES = int(os.getenv("UDID_EXPIRATION_MINUTES", "5"))  # Default: 15 min, para pruebas: 60 min
UDID_MAX_ATTEMPTS = int(os.getenv("UDID_MAX_ATTEMPTS", "5"))  # Default: 5 intentos, para pruebas: 10 intentos

# Configuración del semáforo global de concurrencia
# Configuración estándar: 1000 slots simultáneos
# Configuración optimizada para 32GB RAM / 32 cores / 3000 requests: 3000 slots
# Configuración optimizada para 64GB RAM / 32 cores / 5000-7000 requests: 5000 slots
# Configuración optimizada para 124GB RAM / 64 cores / 10000-15000 requests: 10000 slots
GLOBAL_SEMAPHORE_SLOTS = int(os.getenv("GLOBAL_SEMAPHORE_SLOTS", "1000"))  # Máximo de slots simultáneos

# Límites de WebSocket reducidos para reducir carga del servidor
UDID_WS_MAX_PER_TOKEN = int(os.getenv("UDID_WS_MAX_PER_TOKEN", "1"))  # Reducido de 3 a 1 conexiones por dispositivo/UDID

# Circuit breaker para Redis
# Aumentado threshold a 10 para ser menos sensible durante picos de carga
REDIS_CIRCUIT_BREAKER_THRESHOLD = int(os.getenv("REDIS_CIRCUIT_BREAKER_THRESHOLD", "10"))  # Fallos consecutivos
REDIS_CIRCUIT_BREAKER_TIMEOUT = int(os.getenv("REDIS_CIRCUIT_BREAKER_TIMEOUT", "30"))  # Segundos (reducido para recuperación más rápida)


# ============================================================================
# FASE 2: Backpressure y Degradación
# ============================================================================

# Configuración de la cola de requests
# Configuración estándar: 1000 requests en cola
# Configuración optimizada para 32GB RAM / 32 cores / 3000 requests: 5000 requests
# Configuración optimizada para 64GB RAM / 32 cores / 5000-7000 requests: 10000 requests
# Configuración optimizada para 124GB RAM / 64 cores / 10000-15000 requests: 20000 requests
REQUEST_QUEUE_MAX_SIZE = int(os.getenv("REQUEST_QUEUE_MAX_SIZE", "1000"))
REQUEST_QUEUE_MAX_WAIT_TIME = int(os.getenv("REQUEST_QUEUE_MAX_WAIT_TIME", "10"))  # Segundos

# Configuración de degradación elegante
DEGRADATION_BASELINE_LOAD = int(os.getenv("DEGRADATION_BASELINE_LOAD", "100"))  # Carga base (concurrentes)
DEGRADATION_MEDIUM_THRESHOLD = float(os.getenv("DEGRADATION_MEDIUM_THRESHOLD", "1.5"))  # 1.5x carga base
DEGRADATION_HIGH_THRESHOLD = float(os.getenv("DEGRADATION_HIGH_THRESHOLD", "2.0"))  # 2.0x carga base
DEGRADATION_CRITICAL_THRESHOLD = float(os.getenv("DEGRADATION_CRITICAL_THRESHOLD", "3.0"))  # 3.0x carga base




# ============================================================================
# MIDDLEWARE
# ============================================================================

MIDDLEWARE = [
    "django.middleware.security.SecurityMiddleware",
    "corsheaders.middleware.CorsMiddleware",
    "udid.middleware.SystemLoadTrackingMiddleware",
    "udid.middleware.GlobalConcurrencyMiddleware",
    "udid.middleware.BackpressureMiddleware",
    "udid.middleware.APIKeyAuthMiddleware",
    "django.contrib.sessions.middleware.SessionMiddleware",
    "django.middleware.common.CommonMiddleware",
    "django.middleware.csrf.CsrfViewMiddleware",
    "django.contrib.auth.middleware.AuthenticationMiddleware",
    "django.contrib.messages.middleware.MessageMiddleware",
    "django.middleware.clickjacking.XFrameOptionsMiddleware",
]

ROOT_URLCONF = 'ubuntu.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'ubuntu.wsgi.application'


# ============================================================================
# BASE DE DATOS
# ============================================================================
# https://docs.djangoproject.com/en/5.2/ref/settings/#databases

# SQLite3
# DATABASES = {
#     'default': {
#         'ENGINE': 'django.db.backends.sqlite3',
#         'NAME': BASE_DIR / 'db.sqlite3',
#         'OPTIONS': {
#             'timeout': 30,  # Aumentar timeout para manejar mejor la concurrencia
#         },
#     }
# }

# Docker Compose Postgres
# DATABASES = {
#     "default": {
#         "ENGINE": "django.db.backends.postgresql",
#         "NAME": os.getenv("POSTGRES_DB", "udid"),
#         "USER": os.getenv("POSTGRES_USER", "udid_user"),
#         "PASSWORD": os.getenv("POSTGRES_PASSWORD", ""),
#         "HOST": os.getenv("POSTGRES_HOST", "localhost"),  # o 'postgres' si corre en Docker
#         "PORT": os.getenv("POSTGRES_PORT", "5432"),
#         "CONN_MAX_AGE": 60,
#     }
# }

# Xampp MariaDB
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.mysql',
        'NAME': 'udid',
        'USER': 'root',
        'PASSWORD': '',
        'HOST': os.getenv("MYSQL_HOST", "127.0.0.1"),  # cambia a "db" si usas docker-compose
        'PORT': os.getenv("MYSQL_PORT", "3307"),
        'OPTIONS': {
            'init_command': "SET sql_mode='STRICT_TRANS_TABLES'",
        },
        # Optimizaciones para mejor rendimiento con carga alta
        'CONN_MAX_AGE': 1000,  # Mantener conexiones vivas por 5 minutos (reducir overhead)
        'AUTOCOMMIT': True,
    }
}

# Heroku Postgres
# DATABASES = {
#     'default': dj_database_url.config()
# }


# Password validation
# https://docs.djangoproject.com/en/5.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# ============================================================================
# CORS Y SEGURIDAD
# ============================================================================

#* CORS settings
CORS_ALLOW_ALL_ORIGINS = False
CORS_ALLOW_CREDENTIALS = True

# DjangoConfig.CORS_ORIGIN_WHITELIST
# Usar la configuración de DjangoConfig que viene de CORS_ALLOWED_ORIGINS en .env
# Si CORS_ORIGIN_WHITELIST está en .env, se usa esa, sino se usa DjangoConfig.CORS_ORIGIN_WHITELIST
_cors_whitelist_env = os.getenv("CORS_ORIGIN_WHITELIST")
if _cors_whitelist_env:
    CORS_ORIGIN_WHITELIST = [origin.strip() for origin in _cors_whitelist_env.split(",") if origin.strip()]
elif DjangoConfig.CORS_ORIGIN_WHITELIST:
    # Usar la configuración de DjangoConfig (viene de CORS_ALLOWED_ORIGINS en .env)
    CORS_ORIGIN_WHITELIST = DjangoConfig.CORS_ORIGIN_WHITELIST
else:
    # Lista por defecto si no está configurado
    CORS_ORIGIN_WHITELIST = [
        'http://localhost:8000',
        'http://127.0.0.1:8000',
        'http://localhost:3000',
        'http://localhost:5173',
        'https://front-udid-eta.vercel.app',
    ]

CORS_ALLOW_HEADERS = [
    'accept',               # Tipo de contenido que el cliente acepta recibir
    'accept-encoding',      # Codificaciones de contenido que el cliente acepta (gzip, deflate, etc.)
    'authorization',        # Token de autenticación (Bearer token, JWT, etc.)
    'content-type',         # Tipo de contenido del cuerpo de la petición (application/json, etc.)
    'dnt',                  # Do Not Track: indica la preferencia del usuario sobre el rastreo
    'origin',               # Origen de la petición (protocolo, dominio y puerto)
    'user-agent',           # Información del navegador/cliente que realiza la petición
    'x-csrftoken',          # Token CSRF para protección contra ataques Cross-Site Request Forgery
    'x-requested-with',     # Indica que la petición fue realizada mediante XMLHttpRequest (AJAX)
    'content-encoding',     # Codificación del contenido del cuerpo de la petición
    'x-udid',               # Header personalizado para UDID (Unique Device Identifier)
    'x-app-version',        # Versión de la aplicación móvil o cliente
    'x-device-id',          # Identificador único del dispositivo
    'x-app-type',           # Tipo de aplicación (iOS, Android, Web, etc.)
    'x-os-version',         # Versión del sistema operativo del dispositivo
    'x-device-model',       # Modelo del dispositivo (iPhone 12, Samsung Galaxy S21, etc.)
    'x-build-id',           # Build fingerprint (Android) - identificador único de la compilación
    'x-tv-serial',          # Número de serie del dispositivo Smart TV
    'x-tv-model',           # Modelo específico del Smart TV
    'x-firmware-version',   # Versión de firmware del dispositivo (especialmente para Smart TVs)
    'x-api-key',            # API key para autenticación de la aplicación cliente
    'x-mac-address',        # Dirección MAC del dispositivo (identificador de red)
    'x-device-fingerprint', # Fingerprint generado localmente en el dispositivo para identificación única
]

#* Configurar Seguridad para API Server
SECURE_BROWSER_XSS_FILTER = True
SECURE_CONTENT_TYPE_NOSNIFF = True
SESSION_COOKIE_SECURE = True
CSRF_COOKIE_SECURE = False  # Para APIs móviles
CSRF_USE_SESSIONS = False
X_FRAME_OPTIONS = 'DENY'
SECURE_PROXY_SSL_HEADER = ("HTTP_X_FORWARDED_PROTO", "https")

# Configuración específica para APIs móviles
# Si CSRF_TRUSTED_ORIGINS está en .env, se usa esa, sino se usa la lista por defecto
_csrf_trusted_env = os.getenv("CSRF_TRUSTED_ORIGINS")
if _csrf_trusted_env:
    CSRF_TRUSTED_ORIGINS = [origin.strip() for origin in _csrf_trusted_env.split(",") if origin.strip()]
else:
    # Lista por defecto si no está en .env
    CSRF_TRUSTED_ORIGINS = [
        'https://delancer-c121eb70d8e2.herokuapp.com',
        'https://*.herokuapp.com',
    ]


# ============================================================================
# STATIC FILES / LOCALIZACIÓN
# ============================================================================

# Internationalization
# https://docs.djangoproject.com/en/5.2/topics/i18n/

LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = True
USE_L10N = True
USE_TZ = False

# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/5.2/howto/static-files/

STATIC_URL = 'static/'
STATIC_ROOT = BASE_DIR / 'staticfiles'

# Default primary key field type
# https://docs.djangoproject.com/en/5.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'


# ============================================================================
# REST FRAMEWORK / JWT
# ============================================================================


#* Configurar Django Rest Framework
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': int(os.getenv("REST_FRAMEWORK_PAGE_SIZE", "100")),
    'DEFAULT_FILTER_BACKENDS': [
        'django_filters.rest_framework.DjangoFilterBackend',
        'rest_framework.filters.SearchFilter',
    ],
}

#* Configuración de JWT
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(minutes=int(os.getenv("JWT_ACCESS_TOKEN_LIFETIME_MINUTES", "15"))),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=int(os.getenv("JWT_REFRESH_TOKEN_LIFETIME_DAYS", "1"))),
    'ROTATE_REFRESH_TOKENS': os.getenv("JWT_ROTATE_REFRESH_TOKENS", "True").lower() == "true",
    'BLACKLIST_AFTER_ROTATION': os.getenv("JWT_BLACKLIST_AFTER_ROTATION", "True").lower() == "true",
}

# ============================================================================
# LOGGING
# ============================================================================

#* Configuracion de LOGGING
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'verbose': {
            'format': '[{levelname}] {asctime} {name} {message}',
            'style': '{',
        },
    },
    'handlers': {
        'file': {
            'level': 'DEBUG',
            'class': 'logging.FileHandler',
            'filename': BASE_DIR / 'server.log',
            'formatter': 'verbose',
            'encoding': 'utf-8',  # Asegurar UTF-8 en archivos de log
        },
        'console': {
            'class': 'udid.utils.server.logging_handlers.SafeConsoleHandler',
            'level': 'DEBUG',
            'formatter': 'verbose',
        },
    },
    'root': {
        'handlers': ['file', 'console'],
        'level': 'DEBUG' if DEBUG else 'INFO',
    },
    'loggers': {
        'django': {
            'handlers': ['file', 'console'],
            'level': 'INFO',
            'propagate': False,
        },
        'auth': {
            'handlers': ['file', 'console'],
            'level': 'DEBUG',
            'propagate': True,
        },
        'smartcard': {
            'handlers': ['file', 'console'],
            'level': 'DEBUG',
            'propagate': True,
        },
        # Logger para todas las tareas de Celery en udid
        'udid': {
            'handlers': ['file', 'console'],
            'level': 'DEBUG',
            'propagate': False,
        },
        'udid.tasks': {
            'handlers': ['file', 'console'],
            'level': 'DEBUG',
            'propagate': False,
        },
        # Logger para Celery (tareas, workers, etc.)
        'celery': {
            'handlers': ['file', 'console'],
            'level': 'INFO',
            'propagate': False,
        },
        'celery.task': {
            'handlers': ['file', 'console'],
            'level': 'DEBUG',
            'propagate': False,
        },
    },
}

import logging.config
logging.config.dictConfig(LOGGING)

# ============================================================================
# CELERY CONFIGURATION
# ============================================================================
# * Configuración de Celery para tareas asíncronas y periódicas
# Celery permite ejecutar tareas en background de forma escalable

# Broker: Redis (ya configurado en el proyecto)
CELERY_BROKER_URL = CeleryConfig.BROKER_URL

# Backend de resultados: Redis (base de datos diferente para evitar conflictos)
CELERY_RESULT_BACKEND = CeleryConfig.RESULT_BACKEND

# Serialización (json es más seguro que pickle)
CELERY_TASK_SERIALIZER = CeleryConfig.TASK_SERIALIZER
CELERY_RESULT_SERIALIZER = CeleryConfig.RESULT_SERIALIZER
CELERY_ACCEPT_CONTENT = CeleryConfig.ACCEPT_CONTENT

# Timezone
CELERY_TIMEZONE = CeleryConfig.TIMEZONE
CELERY_ENABLE_UTC = CeleryConfig.ENABLE_UTC

# Configuración de conexión al broker (reintentos automáticos)
CELERY_BROKER_CONNECTION_RETRY_ON_STARTUP = True  # Reconectar automáticamente al iniciar
CELERY_BROKER_CONNECTION_RETRY = True  # Reintentar conexión si se pierde
CELERY_BROKER_CONNECTION_MAX_RETRIES = 10  # Máximo de reintentos

# Configuración de resultados
CELERY_RESULT_EXPIRES = CeleryConfig.RESULT_EXPIRES
CELERY_RESULT_PERSISTENT = CeleryConfig.RESULT_PERSISTENT
CELERY_RESULT_EXTENDED = True  # Incluir más información en los resultados

# Configuración de tareas
CELERY_TASK_TRACK_STARTED = CeleryConfig.TASK_TRACK_STARTED
CELERY_TASK_TIME_LIMIT = CeleryConfig.TASK_TIME_LIMIT
CELERY_TASK_SOFT_TIME_LIMIT = CeleryConfig.TASK_SOFT_TIME_LIMIT
CELERY_TASK_ACKS_LATE = CeleryConfig.TASK_ACKS_LATE
CELERY_TASK_REJECT_ON_WORKER_LOST = CeleryConfig.TASK_REJECT_ON_WORKER_LOST
CELERY_TASK_IGNORE_RESULT = False  # Por defecto, guardar resultados (las tareas pueden sobrescribir esto)

# Configuración para desarrollo (SIEMPRE False en producción)
CELERY_TASK_ALWAYS_EAGER = False  # False = ejecutar en background, True = ejecutar sincrónicamente
CELERY_TASK_EAGER_PROPAGATES = True  # Propagar excepciones en modo eager

# Configuración de workers
# Configuración estándar: prefetch_multiplier = 4
# Configuración optimizada para 32GB RAM / 32 cores: prefetch_multiplier = 8
# Configuración optimizada para 64GB RAM / 32 cores: prefetch_multiplier = 10
# Configuración optimizada para 124GB RAM / 64 cores: prefetch_multiplier = 16
CELERY_WORKER_PREFETCH_MULTIPLIER = int(os.getenv("CELERY_WORKER_PREFETCH_MULTIPLIER", str(CeleryConfig.WORKER_PREFETCH_MULTIPLIER)))
CELERY_WORKER_MAX_TASKS_PER_CHILD = CeleryConfig.WORKER_MAX_TASKS_PER_CHILD
CELERY_WORKER_DISABLE_RATE_LIMITS = CeleryConfig.WORKER_DISABLE_RATE_LIMITS
CELERY_WORKER_SEND_TASK_EVENTS = True  # Enviar eventos de tareas (necesario para Flower)
CELERY_WORKER_DIRECT = False  # Usar AMQP direct (False para Redis)

# Configuración de concurrencia de workers (número de procesos/threads por worker)
# Configuración estándar: auto (detecta automáticamente)
# Configuración optimizada para 32GB RAM / 32 cores: 8-16 workers
# Configuración optimizada para 64GB RAM / 32 cores: 16-24 workers
# Configuración optimizada para 124GB RAM / 64 cores: 32-48 workers
# Nota: Esto se configura al iniciar el worker con: celery -A ubuntu worker --concurrency=N
CELERY_WORKER_CONCURRENCY = int(os.getenv("CELERY_WORKER_CONCURRENCY", "0"))  # 0 = auto

# Configuración de reintentos
CELERY_TASK_DEFAULT_RETRY_DELAY = CeleryConfig.TASK_DEFAULT_RETRY_DELAY
CELERY_TASK_MAX_RETRIES = CeleryConfig.TASK_MAX_RETRIES

# Configuración de colas (routing)
CELERY_TASK_DEFAULT_QUEUE = CeleryConfig.TASK_DEFAULT_QUEUE
CELERY_TASK_DEFAULT_EXCHANGE = CeleryConfig.TASK_DEFAULT_EXCHANGE
CELERY_TASK_DEFAULT_ROUTING_KEY = CeleryConfig.TASK_DEFAULT_ROUTING_KEY

# Configuración de beat (tareas periódicas)
# Ruta completa para el archivo de schedule de Beat (se guarda en /var/run/udid/)
CELERY_BEAT_SCHEDULE_FILENAME = os.path.join(
    os.getenv("CELERY_BEAT_SCHEDULE_DIR", "/var/run/udid"),
    CeleryConfig.BEAT_SCHEDULE_FILENAME
)

# Configuración de monitoreo (Flower)
CELERY_FLOWER_PORT = CeleryConfig.FLOWER_PORT
CELERY_FLOWER_BASIC_AUTH = CeleryConfig.FLOWER_BASIC_AUTH

# Configuración de Beat Schedule (tareas periódicas)
# Define cuándo se ejecutan las tareas automáticamente
from celery.schedules import crontab

CELERY_BEAT_SCHEDULE = {
    # ========================================================================
    # TAREAS PERIÓDICAS AUTOMÁTICAS
    # ========================================================================
    
    # 1. Descargar nuevos suscriptores cada 5 minutos
    # Mantiene la base de datos actualizada con nuevos suscriptores y sus credenciales
    # Frecuencia alta para detectar nuevos registros rápidamente
    'download-new-subscribers-every-5-minutes': {
        'task': 'udid.tasks.download_new_subscribers',
        'schedule': 50.0,  # 300 segundos = 5 minutos
        'options': {'expires': 600},  # Expira después de 10 minutos si no se ejecuta
    },
    
    # 2. Actualizar todos los suscriptores cada 5 minutos
    # Actualiza datos existentes de suscriptores, credenciales e información consolidada
    # Frecuencia alta para mantener datos actualizados en tiempo casi real
    'update-all-subscribers-every-5-minutes': {
        'task': 'udid.tasks.update_all_subscribers',
        'schedule': 300.0,  # 300 segundos = 5 minutos
        'options': {'expires': 600},  # Expira después de 10 minutos si no se ejecuta
    },
    
    # 3. Actualizar smartcards desde suscriptores cada 5 minutos
    # Corrige inconsistencias entre ListOfSubscriber y ListOfSmartcards
    # Frecuencia alta para mantener consistencia entre tablas
    'update-smartcards-from-subscribers-every-5-minutes': {
        'task': 'udid.tasks.update_smartcards_from_subscribers',
        'schedule': 300.0,  # 300 segundos = 5 minutos
        'options': {'expires': 600},  # Expira después de 10 minutos si no se ejecuta
    },
    
    # 4. Validación y corrección completa diaria a las 2:00 AM
    # Esta tarea sincroniza y valida todos los datos desde Panaccess
    # Es la tarea más completa y exhaustiva, se ejecuta en horario de bajo tráfico
    'validate-and-fix-all-data-daily': {
        'task': 'udid.tasks.validate_and_fix_all_data',
        'schedule': crontab(hour=2, minute=0),  # 2:00 AM todos los días
        'options': {'expires': 3600},  # Expira después de 1 hora si no se ejecuta
    },
}

# ============================================================================
# CACHE: Redis distribuido (opcional)
# ============================================================================

#* Configuración de cache para Django
# Migrado a Redis distribuido para rate limiting entre múltiples instancias
if REDIS_URL:
    # Usar Redis como cache backend (distribuido)
    # Verificar si django-redis está instalado
    try:
        import django_redis
        # Usar django-redis si está disponible (mejor para producción)
        CACHES = {
            'default': {
                'BACKEND': 'django_redis.cache.RedisCache',
                'LOCATION': REDIS_URL,
                'OPTIONS': {
                    'CLIENT_CLASS': 'django_redis.client.DefaultClient',
                    'SOCKET_CONNECT_TIMEOUT': int(os.getenv("CACHE_SOCKET_CONNECT_TIMEOUT", "5")),
                    'SOCKET_TIMEOUT': int(os.getenv("CACHE_SOCKET_TIMEOUT", "5")),
                    'COMPRESSOR': 'django_redis.compressors.zlib.ZlibCompressor',
                    'IGNORE_EXCEPTIONS': True,  # Continuar si Redis falla (fallback a BD)
                    # Configuración de pool de conexiones para cache
                    # Configuración estándar: pool por defecto
                    # Configuración optimizada para 32GB RAM / 32 cores: max_connections = 50
                    # Configuración optimizada para 64GB RAM / 32 cores: max_connections = 100
                    # Configuración optimizada para 124GB RAM / 64 cores: max_connections = 150
                    'CONNECTION_POOL_KWARGS': {
                        'max_connections': int(os.getenv("CACHE_MAX_CONNECTIONS", "50")),
                        'retry_on_timeout': True,
                    },
                },
                'KEY_PREFIX': os.getenv("CACHE_KEY_PREFIX", "udid_cache"),
                'TIMEOUT': int(os.getenv("CACHE_TIMEOUT", "300")),  # 5 minutos por defecto
            }
        }
    except ImportError:
        # Fallback al backend nativo de Django (sin CLIENT_CLASS)
        CACHES = {
            'default': {
                'BACKEND': 'django.core.cache.backends.redis.RedisCache',
                'LOCATION': REDIS_URL,
                'OPTIONS': {
                    'SOCKET_CONNECT_TIMEOUT': int(os.getenv("CACHE_SOCKET_CONNECT_TIMEOUT", "5")),
                    'SOCKET_TIMEOUT': int(os.getenv("CACHE_SOCKET_TIMEOUT", "5")),
                    'IGNORE_EXCEPTIONS': True,  # Continuar si Redis falla (fallback a BD)
                    # Configuración de pool de conexiones para cache
                    # Configuración estándar: pool por defecto
                    # Configuración optimizada para 32GB RAM / 32 cores: max_connections = 50
                    # Configuración optimizada para 64GB RAM / 32 cores: max_connections = 100
                    # Configuración optimizada para 124GB RAM / 64 cores: max_connections = 150
                    'CONNECTION_POOL_KWARGS': {
                        'max_connections': int(os.getenv("CACHE_MAX_CONNECTIONS", "50")),
                        'retry_on_timeout': True,
                    },
                },
                'KEY_PREFIX': os.getenv("CACHE_KEY_PREFIX", "udid_cache"),
                'TIMEOUT': int(os.getenv("CACHE_TIMEOUT", "300")),  # 5 minutos por defecto
            }
        }
else:
    # Fallback a cache local si Redis no está disponible (solo para desarrollo)
    # ⚠️ ADVERTENCIA: En producción con múltiples instancias, esto causará problemas
    # de rate limiting. Asegúrate de configurar REDIS_URL.
    CACHES = {
        'default': {
            'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',
            'LOCATION': 'unique-snowflake',
            'TIMEOUT': int(os.getenv("CACHE_TIMEOUT", "300")),
            'OPTIONS': {
                'MAX_ENTRIES': 1000,
                'CULL_FREQUENCY': 3,
            }
        }
    }